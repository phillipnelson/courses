{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glassdoor Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salary Prediction Model\n",
    "\n",
    "WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup\n",
    "\n",
    "We need to import all the modules we'll be using from numpy, scipy, and keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy.io import mmread\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "\n",
    "\n",
    "import keras\n",
    "import json\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/phillip/Code/ai/fastai-courses/experiments'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Location of data directory and load training matrix into sparse matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/phillip/Data/salary-estimates'\n",
    "sparse_training_matrix = mmread('%s/training-matrix-test.txt' % data_dir)\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sparse matrix text = training row + \" \" + column (where value is +1)\n",
    "\n",
    "Notes:\n",
    "\n",
    "'''\n",
    "a.todense() or a.M - Return a dense matrix representation of this matrix. (numpy.matrix)\n",
    "a.A - Return a dense ndarray representation of this matrix. (numpy.array)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6516817, 1812571)\n",
      "  (0, 0)\t1.0\n",
      "  (0, 0)\tTrue\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print sparse_training_matrix.shape\n",
    "print sparse_training_matrix.getrow(568370)\n",
    "print coo_matrix(sparse_training_matrix.getrow(568370), dtype=np.bool)\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "118\n",
      "50000\n",
      "4\n",
      "Created salaries\n"
     ]
    }
   ],
   "source": [
    "def salaryToTarget(salary):\n",
    "    return int(round((max((min((salary * 1.0, 600000.0)), 15000))-15000) / 5000, 0)) + 1\n",
    "\n",
    "def targetToSalary(target):\n",
    "    return ((target - 1) * 5000) + 15000\n",
    "\n",
    "def logSalaryToTarget(logSalary):\n",
    "    return salaryToTarget(math.pow(math.e, logSalary))\n",
    "\n",
    "print salaryToTarget(15000)\n",
    "print salaryToTarget(25000)\n",
    "print salaryToTarget(2500000)\n",
    "print targetToSalary(8)\n",
    "print logSalaryToTarget(10.3089859934221)\n",
    "\n",
    "salaries = np.zeros((6516817, 118), dtype=np.bool)\n",
    "\n",
    "with open('%s/log-salaries-test-truncated.csv' % data_dir,'r') as dest_f:\n",
    "    data_iter = csv.reader(dest_f)\n",
    "    for row in data_iter:\n",
    "        x_index = int(row[0])\n",
    "        if x_index < 6516817:\n",
    "            salaries[x_index][logSalaryToTarget(float(row[1]))] = True \n",
    "    \n",
    "print \"Created salaries\"\n",
    "    \n",
    "#targets = mmread('%s/training-matrix.txt' % data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation\n",
    "\n",
    "### Features\n",
    "\n",
    "- Binary vector of length 1812571 \n",
    "- Each row is a \n",
    "\n",
    "### Training Data\n",
    "\n",
    "- Log salary\n",
    "- Salaries: $15K => $600K\n",
    "- Divide into classes of $5K ranges => 117 classes\n",
    "\n",
    "### Targets\n",
    "\n",
    "- 118 length vector\n",
    "- Note: 0 should be ignored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(layers, model, filters):\n",
    "    for i in range(layers): \n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and here's the fully-connected definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCBlock(model):\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PhillipSalary1():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(512, input_shape=(1812571,)))\n",
    "    # todo this is definitely not correct\n",
    "    #ConvBlock(3, model, 128)\n",
    "    #model.add(Flatten())\n",
    "    #FCBlock(model)\n",
    "    #FCBlock(model)\n",
    "    model.add(Dense(118, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll learn about what these different blocks do later in the course. For now, it's enough to know that:\n",
    "\n",
    "- Convolution layers are for finding patterns in images\n",
    "- Dense (fully connected) layers are for combining patterns across an image\n",
    "\n",
    "Now that we've defined the architecture, we can create the model like any python object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PhillipSalary1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as the architecture, we need the weights that the VGG creators trained. The weights are the part of the model that is learnt from the data, whereas the architecture is pre-defined based on the nature of the problem. \n",
    "\n",
    "Downloading pre-trained weights is much preferred to training the model ourselves, since otherwise we would have to download the entire Imagenet archive, and train the model for many days! It's very helpful when researchers release their weights, as they did here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Salary Matrix: \n",
      "[[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False  True ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "Finished CSR Training Matrix\n",
      "[[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "Training Set: 10\n",
      "Features: 1\n"
     ]
    }
   ],
   "source": [
    "### TESTING: Going to create a new training matrix with 10 rows\n",
    "\n",
    "test_y = salaries[:10]\n",
    "print \"Finished Salary Matrix: \"\n",
    "\n",
    "print test_y\n",
    "\n",
    "#test_x = [] \n",
    "\n",
    "\n",
    "\n",
    "csr_sparse_training_matrix = csr_matrix(sparse_training_matrix, dtype=np.bool)\n",
    "test_x = csr_sparse_training_matrix[:10].todense()\n",
    "\n",
    "print \"Finished CSR Training Matrix\"\n",
    "\n",
    "print test_x\n",
    "\n",
    "#test_x.shape\n",
    "#for n in range(10)\n",
    "print \"Training Set: %s\" % len(test_x)\n",
    "\n",
    "print \"Features: %s\" % len(test_x[0])\n",
    "\n",
    "#y = np.zeros(118, dtype=np.int32)\n",
    "#y[18] = 1\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 110s - loss: 4.2938 - acc: 0.1000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 116s - loss: 4.2898 - acc: 0.3000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 118s - loss: 4.2859 - acc: 0.3000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 103s - loss: 4.2820 - acc: 0.3000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 133s - loss: 4.2780 - acc: 0.3000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 118s - loss: 4.2741 - acc: 0.3000\n",
      "Epoch 7/10\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=test_x, y=test_y, shuffle=\"batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "nav_menu": {},
  "nbpresent": {
   "slides": {
    "28b43202-5690-4169-9aca-6b9dabfeb3ec": {
     "id": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "prev": null,
     "regions": {
      "3bba644a-cf4d-4a49-9fbd-e2554428cf9f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f3d3a388-7e2a-4151-9b50-c20498fceacc",
        "part": "whole"
       },
       "id": "3bba644a-cf4d-4a49-9fbd-e2554428cf9f"
      }
     }
    },
    "8104def2-4b68-44a0-8f1b-b03bf3b2a079": {
     "id": "8104def2-4b68-44a0-8f1b-b03bf3b2a079",
     "prev": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "regions": {
      "7dded777-1ddf-4100-99ae-25cf1c15b575": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fe47bd48-3414-4657-92e7-8b8d6cb0df00",
        "part": "whole"
       },
       "id": "7dded777-1ddf-4100-99ae-25cf1c15b575"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
