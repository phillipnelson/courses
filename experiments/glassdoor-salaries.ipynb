{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glassdoor Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salary Prediction Model\n",
    "\n",
    "WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup\n",
    "\n",
    "We need to import all the modules we'll be using from numpy, scipy, and keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy.io import mmread\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "\n",
    "\n",
    "import keras\n",
    "import json\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/phillip/Code/ai/fastai-courses/experiments'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Location of data directory and load training matrix into sparse matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/phillip/Data/salary-estimates'\n",
    "sparse_training_matrix = mmread('%s/training-matrix-test.txt' % data_dir)\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sparse matrix text = training row + \" \" + column (where value is +1)\n",
    "\n",
    "Notes:\n",
    "\n",
    "'''\n",
    "a.todense() or a.M - Return a dense matrix representation of this matrix. (numpy.matrix)\n",
    "a.A - Return a dense ndarray representation of this matrix. (numpy.array)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6516817, 1812571)\n",
      "  (0, 0)\t1.0\n",
      "  (0, 0)\tTrue\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print sparse_training_matrix.shape\n",
    "print sparse_training_matrix.getrow(568370)\n",
    "print coo_matrix(sparse_training_matrix.getrow(568370), dtype=np.bool)\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "118\n",
      "50000\n",
      "4\n",
      "Created salaries\n"
     ]
    }
   ],
   "source": [
    "def salaryToTarget(salary):\n",
    "    return int(round((max((min((salary * 1.0, 600000.0)), 15000))-15000) / 5000, 0)) + 1\n",
    "\n",
    "def targetToSalary(target):\n",
    "    return ((target - 1) * 5000) + 15000\n",
    "\n",
    "def logSalaryToTarget(logSalary):\n",
    "    return salaryToTarget(math.pow(math.e, logSalary))\n",
    "\n",
    "print salaryToTarget(15000)\n",
    "print salaryToTarget(25000)\n",
    "print salaryToTarget(2500000)\n",
    "print targetToSalary(8)\n",
    "print logSalaryToTarget(10.3089859934221)\n",
    "\n",
    "salaries = np.zeros((6516817, 118), dtype=np.bool)\n",
    "\n",
    "with open('%s/log-salaries-test-truncated.csv' % data_dir,'r') as dest_f:\n",
    "    data_iter = csv.reader(dest_f)\n",
    "    for row in data_iter:\n",
    "        x_index = int(row[0])\n",
    "        if x_index < 6516817:\n",
    "            salaries[x_index][logSalaryToTarget(float(row[1]))] = True \n",
    "    \n",
    "print \"Created salaries\"\n",
    "    \n",
    "#targets = mmread('%s/training-matrix.txt' % data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation\n",
    "\n",
    "### Features\n",
    "\n",
    "- Binary vector of length 1812571 \n",
    "- Each row is a \n",
    "\n",
    "### Training Data\n",
    "\n",
    "- Log salary\n",
    "- Salaries: $15K => $600K\n",
    "- Divide into classes of $5K ranges => 117 classes\n",
    "\n",
    "### Targets\n",
    "\n",
    "- 118 length vector\n",
    "- Note: 0 should be ignored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(layers, model, filters):\n",
    "    for i in range(layers): \n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and here's the fully-connected definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCBlock(model):\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PhillipSalary1():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(512, input_shape=(1812571,)))\n",
    "    # todo this is definitely not correct\n",
    "    #ConvBlock(3, model, 128)\n",
    "    #model.add(Flatten())\n",
    "    #FCBlock(model)\n",
    "    #FCBlock(model)\n",
    "    model.add(Dense(118, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll learn about what these different blocks do later in the course. For now, it's enough to know that:\n",
    "\n",
    "- Convolution layers are for finding patterns in images\n",
    "- Dense (fully connected) layers are for combining patterns across an image\n",
    "\n",
    "Now that we've defined the architecture, we can create the model like any python object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PhillipSalary1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as the architecture, we need the weights that the VGG creators trained. The weights are the part of the model that is learnt from the data, whereas the architecture is pre-defined based on the nature of the problem. \n",
    "\n",
    "Downloading pre-trained weights is much preferred to training the model ourselves, since otherwise we would have to download the entire Imagenet archive, and train the model for many days! It's very helpful when researchers release their weights, as they did here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Salary Matrix: \n",
      "[[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "Finished CSR Training Matrix\n",
      "  (9, 12)\tTrue\n",
      "  (11, 12)\tTrue\n",
      "  (16, 12)\tTrue\n",
      "  (18, 12)\tTrue\n",
      "  (19, 12)\tTrue\n",
      "  (39, 198)\tTrue\n",
      "  (49, 198)\tTrue\n",
      "  (54, 77)\tTrue\n",
      "  (55, 168)\tTrue\n",
      "  (64, 168)\tTrue\n",
      "  (65, 77)\tTrue\n",
      "  (66, 145)\tTrue\n",
      "  (67, 168)\tTrue\n",
      "  (68, 145)\tTrue\n",
      "  (72, 77)\tTrue\n",
      "  (80, 77)\tTrue\n",
      "  (82, 76)\tTrue\n",
      "  (86, 77)\tTrue\n",
      "  (89, 168)\tTrue\n",
      "  (93, 77)\tTrue\n",
      "Training Set: 100\n",
      "Features: 1812571\n"
     ]
    }
   ],
   "source": [
    "### TESTING: Going to create a new training matrix with 10 rows\n",
    "\n",
    "test_y = salaries[:100]\n",
    "\n",
    "print \"Finished Salary Matrix: \"\n",
    "\n",
    "print test_y\n",
    "\n",
    "#test_x = [] \n",
    "\n",
    "\n",
    "\n",
    "csr_sparse_training_matrix = csr_matrix(sparse_training_matrix, dtype=np.bool)\n",
    "test_x = csr_sparse_training_matrix[:100]\n",
    "\n",
    "print \"Finished CSR Training Matrix\"\n",
    "\n",
    "print test_x\n",
    "\n",
    "#test_x.shape\n",
    "#for n in range(10)\n",
    "print \"Training Set: %s\" % len(test_x.A)\n",
    "\n",
    "print \"Features: %s\" % len(test_x.A[0])\n",
    "\n",
    "#y = np.zeros(118, dtype=np.int32)\n",
    "#y[18] = 1\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TypeError while preparing batch. If using HDF5 input data, pass shuffle=\"batch\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-aa37405f424f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse_training_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msalaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/phillip/Code/ai/ai-env/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/phillip/Code/ai/ai-env/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1194\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/phillip/Code/ai/ai-env/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    882\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                     raise TypeError('TypeError while preparing batch. '\n\u001b[0m\u001b[1;32m    885\u001b[0m                                     \u001b[0;34m'If using HDF5 input data, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m                                     'pass shuffle=\"batch\".')\n",
      "\u001b[0;31mTypeError\u001b[0m: TypeError while preparing batch. If using HDF5 input data, pass shuffle=\"batch\"."
     ]
    }
   ],
   "source": [
    "history = model.fit(x=sparse_training_matrix, y=salaries, shuffle=\"batch\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "nav_menu": {},
  "nbpresent": {
   "slides": {
    "28b43202-5690-4169-9aca-6b9dabfeb3ec": {
     "id": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "prev": null,
     "regions": {
      "3bba644a-cf4d-4a49-9fbd-e2554428cf9f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f3d3a388-7e2a-4151-9b50-c20498fceacc",
        "part": "whole"
       },
       "id": "3bba644a-cf4d-4a49-9fbd-e2554428cf9f"
      }
     }
    },
    "8104def2-4b68-44a0-8f1b-b03bf3b2a079": {
     "id": "8104def2-4b68-44a0-8f1b-b03bf3b2a079",
     "prev": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "regions": {
      "7dded777-1ddf-4100-99ae-25cf1c15b575": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fe47bd48-3414-4657-92e7-8b8d6cb0df00",
        "part": "whole"
       },
       "id": "7dded777-1ddf-4100-99ae-25cf1c15b575"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
